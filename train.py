import sys

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image, ImageFile
from sklearn.metrics import recall_score

ImageFile.LOAD_TRUNCATED_IMAGES = True
import os
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from torchvision import transforms
import torch.nn.functional as F
import torchvision.transforms.functional as TF

import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import os

from model import resnet34, resnet50, resnet101, resnet18


class ImageDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label


def load_data(data_dir):
    image_paths = []
    labels = []
    class_names = sorted(os.listdir(data_dir))

    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}

    for class_name in class_names:
        class_path = os.path.join(data_dir, class_name)
        if os.path.isdir(class_path):
            for img_name in os.listdir(class_path):
                if img_name.lower().endswith((".png", ".jpg", ".jpeg", ".bmp")):
                    image_paths.append(os.path.join(class_path, img_name))
                    w, h = Image.open(image_paths[-1]).size
                    if w < 512 or h < 512:
                        image_paths.pop()
                        continue
                    labels.append(class_to_idx[class_name])

    return image_paths, labels, class_names

from timm.data import Mixup

# é…ç½® Mixup å’Œ Cutmix
mixup_fn = Mixup(
    mixup_alpha=0.2,       # Mixup å¼ºåº¦ï¼ˆå»ºè®® 0.8ï¼‰
    cutmix_alpha=1.0,      # Cutmix å¼ºåº¦ï¼ˆå»ºè®® 1.0ï¼‰
    prob=0.5,              # æ¯æ¬¡ batch æœ‰å¤šå°‘æ¦‚ç‡è§¦å‘ Mixup/Cutmix
    switch_prob=0.5,       # åœ¨ Mixup å’Œ Cutmix ä¹‹é—´åˆ‡æ¢çš„æ¦‚ç‡
    mode='batch',          # ä»¥ batch ä¸ºå•ä½è¿›è¡Œå˜æ¢
    label_smoothing=0.1,   # æ ‡ç­¾å¹³æ»‘
    num_classes=6          # ä½ çš„åˆ†ç±»æ•°
)

def set_seed(seed: int = 42, deterministic: bool = True):
    import os
    import random
    import numpy as np
    import torch

    # Python & NumPy
    random.seed(seed)
    np.random.seed(seed)

    # PyTorch
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # ç¯å¢ƒå˜é‡ï¼ˆhash & CUDAï¼‰
    os.environ["PYTHONHASHSEED"] = str(seed)

    if deterministic:
        # cuDNN
        torch.backends.cudnn.benchmark = False
        torch.backends.cudnn.deterministic = True

        # PyTorch >= 1.8
        torch.use_deterministic_algorithms(True)

        # CUDA 11+
        os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":16:8"

    else:
        # æ›´å¿«ï¼Œä½†ä¸å¯å¤ç°
        torch.backends.cudnn.benchmark = True


def train_model(
        model,
        train_loader,
        val_loader,
        criterion,
        optimizer,
        num_epochs,
        device,
        train_sampler,
):
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    best_acc = 0.0
    best_recall = 0.0
    save_path = "./resNet34.pth"

    for epoch in tqdm(range(num_epochs)):
        # train_sampler.set_epoch(epoch)
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            ordinal_targets = label_to_ordinal(labels)

            optimizer.zero_grad()
            # samples, targets = mixup_fn(images, labels)
            outputs = model(images)
            # loss = criterion(outputs, labels)

            weights = torch.tensor([1.0, 1.0, 3.0, 1.0, 1.0]).to(device) # ç»™ä¸­é—´ç¥ç»å…ƒ 3 å€æƒé‡
            # æ‰‹åŠ¨è®¡ç®— BCE Loss å¹¶åŠ æƒ
            loss_matrix = F.binary_cross_entropy_with_logits(outputs, ordinal_targets, reduction='none')
            loss = (loss_matrix * weights).mean()

            # loss = criterion(outputs, ordinal_targets)
            # print(loss)
            loss.backward()
            optimizer.step()
            # optimizer.first_step(zero_grad=True)

            # outputs = model(images)
            # criterion(outputs, labels).backward()
            # optimizer.second_step(zero_grad=True)

            probs = torch.sigmoid(outputs) # è½¬æ¢ä¸ºæ¦‚ç‡
            # ç»Ÿè®¡å¤§äº 0.5 çš„ä¸ªæ•°ã€‚ä¾‹å¦‚æœ‰ 2 ä¸ªå¤§äº 0.5ï¼Œè¯´æ˜æ˜¯ C3 (ç´¢å¼•ä¸º2)
            predicted = (probs > 0.5).sum(dim=1)
            # print("predicted: ", predicted.cpu().numpy())
            # print("label: ", labels.cpu().numpy())

            running_loss += loss.item()
            # _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        train_loss = running_loss / len(train_loader)
        train_acc = 100 * correct / total
        train_losses.append(train_loss)
        train_accs.append(train_acc)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        acc = 0.0
        val_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)

                ordinal_targets = label_to_ordinal(labels)

                outputs = model(images)
                loss = criterion(outputs, ordinal_targets)

                probs = torch.sigmoid(outputs) # è½¬æ¢ä¸ºæ¦‚ç‡
                # ç»Ÿè®¡å¤§äº 0.5 çš„ä¸ªæ•°ã€‚ä¾‹å¦‚æœ‰ 2 ä¸ªå¤§äº 0.5ï¼Œè¯´æ˜æ˜¯ C3 (ç´¢å¼•ä¸º2)
                predicted = (probs > 0.5).sum(dim=1)
                # print("predicted: ", predicted.cpu().numpy())
                # print("label: ", labels.cpu().numpy())
                val_loss += loss.item()
                # _, predicted = torch.max(outputs.data, 1)

                acc += torch.eq(predicted, labels).sum().item()
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                all_preds.append(predicted.cpu().numpy())
                all_labels.append(labels.cpu().numpy())

        val_loss = val_loss / len(val_loader)
        val_acc = 100 * correct / total
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        all_preds = np.concatenate(all_preds)
        all_labels = np.concatenate(all_labels)
        # macro recall
        # val_recall = recall_score(all_labels, all_preds, average='macro') * 100

        if val_acc > best_acc:
            best_acc = val_acc
            print("æœ€ä½³æ¨¡å‹å·²æ›´æ–°ï¼Œä¿å­˜ä¸­...")
            torch.save(model.state_dict(), "aug1_new_resnet50_ddp.pth")
                # torch.save(model.state_dict(), save_path)
        # elif val_recall > best_recall:
        #     best_recall = val_recall
        #     if dist.get_rank() == 0:
        #         print("æœ€ä½³æ¨¡å‹å·²æ›´æ–°ï¼Œä¿å­˜ä¸­...")
        #         torch.save(model.module.state_dict(), "new_resnet50_ddp.pth")
        #         # torch.save(model.state_dict(), save_path)


            print(f"Epoch [{epoch}/{num_epochs}]")
            print(f"Epoch [{epoch + 1}/{num_epochs}]")
            print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
            print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
            print("-" * 50)

    return train_losses, val_losses, train_accs, val_accs


def plot_training_curves(train_losses, val_losses, train_accs, val_accs):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    ax1.plot(train_losses, label="Train Loss")
    ax1.plot(val_losses, label="Val Loss")
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss")
    ax1.set_title("Training and Validation Loss")
    ax1.legend()
    ax1.grid(True)

    ax2.plot(train_accs, label="Train Accuracy")
    ax2.plot(val_accs, label="Val Accuracy")
    ax2.set_xlabel("Epoch")
    ax2.set_ylabel("Accuracy (%)")
    ax2.set_title("Training and Validation Accuracy")
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    plt.savefig("training_curves.png")
    plt.show()


class ResizeWithPad:
    def __init__(self, size=224):
        self.size = size

    def __call__(self, img):
        w, h = img.size
        scale = self.size / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        img = TF.resize(img, (new_h, new_w))

        pad_w = self.size - new_w
        pad_h = self.size - new_h
        img = TF.pad(
            img, (pad_w // 2, pad_h // 2, pad_w - pad_w // 2, pad_h - pad_h // 2)
        )
        # img = TF.pad(
        #     img,
        #     (pad_w // 2, pad_h // 2, pad_w - pad_w // 2, pad_h - pad_h // 2),
        #     fill=tuple(int(x * 255) for x in [0.485, 0.456, 0.406]),
        # )
        return img


def setup_ddp():
    """
    å¯åŠ¨å¹¶è¡Œè®­ç»ƒ
    """
    dist.init_process_group(backend="nccl")
    local_rank = int(os.environ["LOCAL_RANK"])
    torch.cuda.set_device(local_rank)
    return local_rank


def freeze_all_except_fc(net):
    for name, param in net.named_parameters():
        if "fc" in name:
            param.requires_grad = True
        else:
            param.requires_grad = False


def unfreeze_layer4_and_fc(net):
    for name, param in net.named_parameters():
        if "layer4" in name or "fc" in name:
            param.requires_grad = True
        else:
            param.requires_grad = False


def unfreeze_all(net):
    for param in net.parameters():
        param.requires_grad = True


def run_one_stage(
        model,
        train_loader,
        val_loader,
        criterion,
        optimizer,
        num_epochs,
        device,
        train_sampler,
        stage_name="",
):
    best_acc = 0.0
    for epoch in range(num_epochs):
        train_sampler.set_epoch(epoch)

        model.train()
        correct, total, running_loss = 0, 0, 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, pred = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (pred == labels).sum().item()

        train_acc = 100 * correct / total

        model.eval()
        correct, total, val_loss = 0, 0, 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, pred = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (pred == labels).sum().item()

        val_acc = 100 * correct / total

        if val_acc > best_acc:
            best_acc = val_acc
            # if dist.get_rank() == 0:
            print("æœ€ä½³æ¨¡å‹å·²æ›´æ–°ï¼Œä¿å­˜ä¸­...")
            torch.save(
                    model.module.state_dict(), stage_name + "new_resnet50_ddp.pth"
                )
                # torch.save(model.state_dict(), save_path)
        # if dist.get_rank() == 0:
        print(f"Epoch [{epoch}/{num_epochs}]")
        print(f"Epoch [{epoch + 1}/{num_epochs}]")
        print(f"Train Loss: {running_loss:.4f}, Train Acc: {train_acc:.2f}%")
        print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        print("-" * 50)
        # if dist.get_rank() == 0:
        print(
                f"[{stage_name}] Epoch {epoch+1}/{num_epochs} "
                f"Train Acc {train_acc:.2f}% | Val Acc {val_acc:.2f}%"
            )


class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2, reduction="mean"):
        super().__init__()
        self.gamma = gamma
        self.reduction = reduction

        if alpha is not None:
            self.alpha = torch.tensor(alpha, dtype=torch.float)
        else:
            self.alpha = None

    def forward(self, logits, targets):
        """
        logits: [B, C]
        targets: [B]  (ç±»åˆ«ç´¢å¼•, 0 ~ C-1)
        """
        log_probs = F.log_softmax(logits, dim=1)
        probs = torch.exp(log_probs)

        # å–å‡ºçœŸå®ç±»åˆ«å¯¹åº”çš„æ¦‚ç‡ p_t
        targets = targets.view(-1, 1)
        pt = probs.gather(1, targets).squeeze(1)
        log_pt = log_probs.gather(1, targets).squeeze(1)

        if self.alpha is not None:
            alpha_t = self.alpha.to(logits.device).gather(0, targets.squeeze(1))
            loss = -alpha_t * (1 - pt) ** self.gamma * log_pt
        else:
            loss = -((1 - pt) ** self.gamma) * log_pt

        if self.reduction == "mean":
            return loss.mean()
        elif self.reduction == "sum":
            return loss.sum()
        else:
            return loss


class SAM(torch.optim.Optimizer):
    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):
        assert rho >= 0.0
        defaults = dict(rho=rho, **kwargs)
        super(SAM, self).__init__(params, defaults)

        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)
        self.rho = rho

    @torch.no_grad()
    def first_step(self, zero_grad=True):
        grad_norm = self._grad_norm()
        for group in self.param_groups:
            scale = self.rho / (grad_norm + 1e-12)
            for p in group["params"]:
                if p.grad is None:
                    continue
                e_w = p.grad * scale.to(p)
                p.add_(e_w)  # climb to the local maximum
                self.state[p]["e_w"] = e_w
        if zero_grad:
            self.zero_grad()

    @torch.no_grad()
    def second_step(self, zero_grad=True):
        for group in self.param_groups:
            for p in group["params"]:
                if p.grad is None:
                    continue
                p.sub_(self.state[p]["e_w"])  # get back to original position
        self.base_optimizer.step()
        if zero_grad:
            self.zero_grad()

    def step(self):
        raise NotImplementedError("SAM requires first_step and second_step")

    def _grad_norm(self):
        device = self.param_groups[0]["params"][0].device
        norms = []
        for group in self.param_groups:
            for p in group["params"]:
                if p.grad is not None:
                    norms.append(p.grad.norm(p=2).to(device))
        if len(norms) == 0:
            return torch.tensor(0.0).to(device)
        return torch.norm(torch.stack(norms), p=2)


class SEBlock(nn.Module):
    """SEæ³¨æ„åŠ›å— - æœ€å¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡"""

    def __init__(self, in_channels, reduction_ratio=16):
        super(SEBlock, self).__init__()
        self.squeeze = nn.AdaptiveAvgPool1d(1)
        self.excitation = nn.Sequential(
            nn.Linear(in_channels, in_channels // reduction_ratio),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels // reduction_ratio, in_channels),
            nn.Sigmoid(),
        )

    def forward(self, x):
        # x shape: (batch, channels)
        batch_size, channels = x.size()

        # Squeeze: å…¨å±€å¹³å‡æ± åŒ–
        y = x.view(batch_size, channels, 1)
        y = self.squeeze(y).view(batch_size, channels)

        # Excitation: å­¦ä¹ é€šé“æƒé‡
        y = self.excitation(y)

        # Scale: é‡æ ‡å®š
        return x * y


class ClassifierWithSE(nn.Module):
    def __init__(self, in_channel, num_classes, dropout_prob=0.5):
        super(ClassifierWithSE, self).__init__()
        self.se = SEBlock(in_channel, reduction_ratio=16)
        self.classifier = nn.Sequential(
            nn.Dropout(p=dropout_prob), nn.Linear(in_channel, num_classes)
        )

    def forward(self, x):
        x = self.se(x)
        x = self.classifier(x)
        return x

import torch.nn.functional as F

def label_to_ordinal(labels, num_classes=6):
    # labels: [batch_size]
    # return: [batch_size, num_classes - 1]
    batch_size = labels.size(0)
    ordinal_labels = torch.zeros(batch_size, num_classes - 1).to(labels.device)
    for i in range(batch_size):
        ordinal_labels[i, :labels[i]] = 1
    return ordinal_labels

class CosineLinear(nn.Module):
    def __init__(self, in_features, out_features, s=30.0):
        super(CosineLinear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.s = s  # ç¼©æ”¾å› å­ï¼Œéå¸¸é‡è¦
        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)

    def forward(self, x):
        # 1. å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–
        x_norm = F.normalize(x, p=2, dim=1)
        # 2. å¯¹æƒé‡è¿›è¡Œå½’ä¸€åŒ–
        w_norm = F.normalize(self.weight, p=2, dim=1)
        # 3. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¹¶ç¼©æ”¾
        # ä½™å¼¦å€¼èŒƒå›´åœ¨ [-1, 1]ï¼Œå¦‚æœä¸ä¹˜ sï¼ŒSoftmax åçš„æ¦‚ç‡åˆ†å¸ƒä¼šå¤ªâ€œå¹³â€ï¼Œå¯¼è‡´ä¸æ”¶æ•›
        logits = torch.mm(x_norm, w_norm.t())
        return self.s * logits

class VaricoseNet(nn.Module):
    def __init__(self, backbone, num_classes=6):
        super().__init__()
        self.backbone = backbone            # DINO ViT
        # print(backbone)

        # self.backbone = resnet34()
        # state = torch.load("./resnet34-pre.pth", map_location="cpu", weights_only=True)
        # self.backbone.load_state_dict(state, strict=False)
        # self.classifier = nn.Sequential(nn.Dropout(p=0.6), nn.Linear(1000, 5))# 0.5æ•ˆæœæœ€å¥½

        for param in self.backbone.parameters():
            param.requires_grad = False

        for param in self.backbone.blocks[-1].parameters():
            param.requires_grad = True

        if hasattr(self.backbone, 'norm'):
            for param in self.backbone.norm.parameters():
                param.requires_grad = True

        embed_dim = 768

        # self.se_module = SEBlock(embed_dim * 2)

        self.norm = nn.LayerNorm(embed_dim * 2)

        self.classifier = nn.Sequential(
            nn.Conv2d(1, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),

            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Dropout(p=0.7),

            # è¿˜åŸä¸ºâ€œé€šé“å‹ç¼©â€
            nn.Conv2d(128, 5, kernel_size=1)
        )

    def forward(self, x):
        features = self.backbone.get_intermediate_layers(x, n=1)[0]

        cls_token = features[:, 0]          # [B, 768]
        patch_tokens = features[:, 1:]      # [B, N, 768]

        gap = torch.mean(patch_tokens, dim=1)   # [B, 768]

        combined = torch.cat([cls_token, gap], dim=1)  # [B, 1536]
        combined = self.norm(combined)

        B = combined.size(0)

    # ğŸ‘‰ reshape æˆ 2D
        combined = combined.view(B, 1, 48, 32)        # [B, 1, 48, 32]

        out = self.classifier(combined)               # [B, 5, 48, 32]

    # ğŸ‘‰ å…¨å±€æ± åŒ–ï¼Œå¾—åˆ°ç±»åˆ« logits
        out = out.mean(dim=(2, 3))                    # [B, 5]

        return out


device = torch.device("cuda")



def main():
    set_seed(42,deterministic=True)
    train_data_dir = "/home/zengwanxin/openworld/vvdata/aug1/" #è¿œç¨‹7ä¸ºaug2 cuda7
    val_data_dir = "./output/val"
    batch_size = 16
    num_epochs = 200
    learning_rate = 0.0001

    # local_rank = setup_ddp()
    # device = torch.device(f"cuda:{local_rank}")

    # device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")



    transform_train = transforms.Compose(
        [
            ResizeWithPad(512),
            transforms.ToTensor(),
            # transforms.CenterCrop((int(0.8 * 384), int(0.8 * 384))),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]
    )

    transform_val = transforms.Compose(
        [
            ResizeWithPad(512),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]
    )

    # åŠ è½½æ•°æ®
    train_image_paths, train_labels, train_class_names = load_data(train_data_dir)
    val_image_paths, val_labels, val_class_names = load_data(val_data_dir)
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_image_paths)}, éªŒè¯æ ·æœ¬æ•°: {len(val_image_paths)}")
    print(f"ç±»åˆ«: {train_class_names}")

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    # train_paths, val_paths, train_labels, val_labels = train_test_split(
    #     image_paths, labels, test_size=0.2, random_state=42, stratify=labels
    # )

    train_dataset = ImageDataset(train_image_paths, train_labels, transform_train)
    val_dataset = ImageDataset(val_image_paths, val_labels, transform_val)

    # train_sampler = DistributedSampler(train_dataset, shuffle=True)
    # val_sampler = DistributedSampler(val_dataset, shuffle=False)

    train_sampler = None
    val_sampler = None

    # train_loader = DataLoader(
    #     train_dataset,
    #     batch_size=8,
    #     sampler=train_sampler,
    #     num_workers=4,
    #     pin_memory=True,
    #     drop_last=True
    # )
    #
    # val_loader = DataLoader(
    #     val_dataset, batch_size=1, sampler=val_sampler, num_workers=4, pin_memory=True
    # )

    train_loader = DataLoader(
        train_dataset,
        batch_size=8,  # åŸç‰ˆä¸º8 è¿œç¨‹æ”¹ä¸º16  è¿œç¨‹2ä¸º32   è¿œç¨‹3ä¸º64 è¿œç¨‹4ä¸º128
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        drop_last=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    net = torch.hub.load("facebookresearch/dino:main", "dino_vitb16")
    model = VaricoseNet(net, num_classes=6)
    model = model.to(device)
    # model = DDP(model, device_ids=[local_rank], find_unused_parameters=True)
    print(model)

    # loss_function = FocalLoss(
    #     alpha=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0], gamma=2  # æŒ‰ä½ CEAPå„çº§æ ·æœ¬æ•°åæ¯”è®¾
    # )
    # weights = torch.tensor([1.5, 1.0, 2.5, 1.2, 3.0,1.0]).cuda()
    # loss_function = nn.CrossEntropyLoss(label_smoothing=0.1)


    loss_function = nn.BCEWithLogitsLoss()
    params = [p for p in model.parameters() if p.requires_grad]

    base_optimizer = torch.optim.AdamW
    # optimizer = SAM(params, base_optimizer, rho=0.05, lr=1e-4, weight_decay=5e-4)

    optimizer = optim.Adam(params, lr=0.001, weight_decay=1e-4) #è¿œç¨‹ä¿®æ”¹å­¦ä¹ ç‡ä¸º0.0001


    # è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹...")
    train_losses, val_losses, train_accs, val_accs = train_model(
        model,
        train_loader,
        val_loader,
        loss_function,
        optimizer,
        num_epochs,
        device,
        train_sampler,
    )

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_curves(train_losses, val_losses, train_accs, val_accs)


if __name__ == "__main__":
    main()
    # eval()